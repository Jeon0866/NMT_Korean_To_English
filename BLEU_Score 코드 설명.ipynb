{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEU\n",
    "\n",
    "출처 : https://donghwa-kim.github.io/BLEU.html\n",
    "\n",
    "- BLEU(Bilingual Evaluation Understudy) score란 성과지표로 데이터의 X가 순서정보를 가진 단어들(문장)로 이루어져 있고, y 또한 단어들의 시리즈(문장)로 이루어진 경우에 사용되며, 번역에 하는 모델에 주로 사용 된다\n",
    "\n",
    "![calculation_bleu](img/bleu_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![description_bleu](img/bleu_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-gram 분석 https://blog.ilkyu.kr/entry/%EC%96%B8%EC%96%B4-%EB%AA%A8%EB%8D%B8%EB%A7%81-ngram\n",
    "\n",
    "#sentence: 분석할 문장, num_gram: n-gram 단위\n",
    "def word_ngram(sentence, num_gram):\n",
    "    # in the case a file is given, remove escape characters\n",
    "    sentence = sentence.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    text = tuple(sentence.split(' '))\n",
    "    ngrams = [text[x:x+num_gram] for x in range(0, len(text)) if x+num_gram <= len(text)]\n",
    "    return list(ngrams)\n",
    "\n",
    "#n-gram 빈도 리스트 생성\n",
    "def make_freqlist(ngrams):\n",
    "    unique_ngrams = list(set(ngrams))\n",
    "    freqlist = [0 for _ in range(len(unique_ngrams))]\n",
    "    for ngram in ngrams:\n",
    "        idx = unique_ngrams.index(ngram)\n",
    "        freqlist[idx] +=1\n",
    "    result = [unique_ngrams, freqlist]\n",
    "    return result\n",
    "\n",
    " \n",
    "# 두개 ngram 얼마나 겹치는지\n",
    "def precision(output, target): # \n",
    "    result = 0\n",
    "    output_len = 0\n",
    "    for i in range(len(output[0])):\n",
    "        if output[0][i] in target[0]:\n",
    "            idx = target[0].index(output[0][i])\n",
    "            result += min(output[1][i], target[1][idx])  # output frequency와 target frequency 중에서 min값 사용(Cliping)\n",
    "    try:\n",
    "        return result / sum(output[1])\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('때',), ('기회가',), ('훨씬',), ('노인은',), ('잠든',), ('완벽한',), ('높았다',), ('심해질',), ('비교할',), ('강박증이',), ('빛이',), ('사람과',), ('어두운곳에서',), ('쐬는',)], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "sentence = '빛이 쐬는 노인은 완벽한 어두운곳에서 잠든 사람과 비교할 때 강박증이 심해질 기회가 훨씬 높았다'\n",
    "a = word_ngram(sentence,1)\n",
    "print(make_freqlist(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict = '빛이 쐬는 노인은 완벽한 어두운곳에서 잠든 사람과 비교할 때 강박증이 심해질 기회가 훨씬 높았다'\n",
    "# true = '빛이 쐬는 노인은 완벽한 어둠에서 잠든 사람과 비교할 때 우울증이 심해질 가능성이 훨씬 높았다'\n",
    "predict = 'The more decomposition the more flavor the food has'\n",
    "true = 'The more the merrier I always say'\n",
    "\n",
    "a = word_ngram(predict, 1)\n",
    "a = make_freqlist(a)\n",
    "b = word_ngram(true, 1)\n",
    "b = make_freqlist(b)\n",
    "precision(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "0.38461538461538464\n",
      "0.16666666666666666\n",
      "0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "print(10/14)\n",
    "print(5/13)\n",
    "print(2/12)\n",
    "print(1/11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "0.38461538461538464\n",
      "0.16666666666666666\n",
      "0.09090909090909091\n",
      "0.25400289715190977\n",
      "0.25400289715190977\n"
     ]
    }
   ],
   "source": [
    "print(n_gram_precision(predict,true))\n",
    "print(1*pow(10*5*2/14/13/12/11, 1/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![description2](img/bleu_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_precision(sen_out, sen_tar):\n",
    "    output = []\n",
    "    target = []\n",
    "    tar_freq = []\n",
    "    sentence = sen_tar.replace('\\n', ' ').replace('\\r', ' ').split(' ')\n",
    "    rouge_n = len(sentence) < 4\n",
    "    if rouge_n:  # 문장 단어의 개수가 4개 미만일 때\n",
    "        max_n = len(sentence) + 1\n",
    "        rouge_list = []\n",
    "    else:\n",
    "        max_n = 5\n",
    "    for i in range(1,max_n):\n",
    "        n_gram = word_ngram(sen_out, i)\n",
    "        out_tmp = make_freqlist(n_gram)\n",
    "        output.append(out_tmp)\n",
    "        n_gram2 = word_ngram(sen_tar, i)\n",
    "        tar_tmp = make_freqlist(n_gram2)\n",
    "        target.append(tar_tmp)\n",
    "    result = 0\n",
    "    n_pre = 0\n",
    "    for i in range(len(output)):\n",
    "        n_pre = precision(output[i], target[i])\n",
    "        if rouge_n:\n",
    "            print(\"ROUGE-\" + str(i+1) + \": \" + str(n_pre))\n",
    "            rouge_list.append(n_pre)\n",
    "        if i == 0:\n",
    "            result = n_pre\n",
    "        else:\n",
    "            result *= n_pre\n",
    "    if rouge_n:\n",
    "        return rouge_list\n",
    "    else:\n",
    "        result = pow(result, 1/(max_n-1))\n",
    "        # Brevity Penalty\n",
    "        bp = min(1, sum(output[0][1])/sum(target[0][1]))\n",
    "        return bp * result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROUGE-N: unigram, bigram, trigram 등 문장 간 중복되는 n-gram을 비교하는 지표입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "ROUGE-1: 1.0\n",
      "ROUGE-2: 1.0\n",
      "[1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "# candidate = 'It is a guide to action which ensures that the military always obeys the commands of the party'\n",
    "# references = 'It is a guide to action that ensures that the military will forever heed Party commands'\n",
    "candidate = '나는 사람이다'\n",
    "references = '나는 사람이다'\n",
    "candidate_corpus = [candidate.split()]\n",
    "references_corpus = [[references.split()]]\n",
    "\n",
    "print(bleu_score(candidate_corpus, references_corpus))\n",
    "print(n_gram_precision(candidate, references))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
